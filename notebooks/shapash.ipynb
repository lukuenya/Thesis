{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapash Model Interpretation Notebook\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "import shapash.explainer.smart_plotter\n",
    "#from shapash.utils.model_synoptic import model_synoptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to path so we can import modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from data_loader import load_data\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to analyze\n",
    "MODELS = ['xgboost', 'lightgbm', 'catboost', 'randomforest']\n",
    "SCORE_TYPES = ['FRIED', 'FRAGIRE18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, score_type):\n",
    "    \"\"\"Load a trained model from disk\"\"\"\n",
    "    model_path = os.path.join(config.MODEL_OUTPUT, 'classifiers', f\"{model_name}_{score_type.lower()}.pkl\")\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = joblib.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if file exists: ../models/classifiers\\lightgbm_fried.pkl\n",
      "File exists: True\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\miniconda3\\envs\\thesis_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator LabelEncoder from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import joblib   \n",
    "\n",
    "# Try with explicit path\n",
    "model_dir = '../models/classifiers'  # Adjust if needed\n",
    "model_file = 'lightgbm_fried.pkl'\n",
    "full_path = os.path.join(model_dir, model_file)\n",
    "\n",
    "print(f\"Checking if file exists: {full_path}\")\n",
    "print(f\"File exists: {os.path.exists(full_path)}\")\n",
    "\n",
    "if os.path.exists(full_path):\n",
    "    with open(full_path, 'rb') as f:\n",
    "        model = joblib.load(f)\n",
    "    print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {0: 'non-frail', 1: 'frail'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model_name, score_type):\n",
    "    \"\"\"Analyze a model using Shapash\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analyzing {model_name.upper()} model for {score_type}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Load the model\n",
    "    try:\n",
    "        model = load_model(model_name, score_type)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file not found for {model_name} - {score_type}\")\n",
    "        return\n",
    "    \n",
    "    # Load the data\n",
    "    X, y = load_data(target_score=score_type, selected_features=False)\n",
    "    \n",
    "    # Convert target to int for classification\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    # Create output directory for Shapash visualizations\n",
    "    output_dir = os.path.join(config.VISUALIZATION_OUTPUT, model_name, score_type.upper(), 'shapash')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create a Shapash SmartExplainer\n",
    "    xpl = SmartExplainer(model=model)\n",
    "    xpl.compile(\n",
    "        label_dict = response_dict,\n",
    "        x=X,\n",
    "        y=y,\n",
    "        preprocessing=None,  # No preprocessing here since X is already processed\n",
    "        features_dict=None,  # Use column names as feature names\n",
    "    )\n",
    "    \n",
    "    # Generate model synoptic (overview)\n",
    "    model_synoptic(model, x=X)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    \n",
    "    # 1. Global feature importance\n",
    "    contrib_plot = xpl.plot.features_importance()\n",
    "    plt.title(f\"Feature Importance - {model_name.upper()} - {score_type}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"feature_importance.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Local explanations for a sample of predictions\n",
    "    # Choose 5 random samples for explanation\n",
    "    sample_indices = np.random.choice(X.shape[0], size=min(5, X.shape[0]), replace=False)\n",
    "    \n",
    "    # Local explanations\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        local_plot = xpl.plot.local_plot(index=idx)\n",
    "        plt.title(f\"Local Explanation - Sample {i+1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"local_explanation_{i+1}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Generate a Shapash report\n",
    "    xpl.save(os.path.join(output_dir, f\"shapash_report_{model_name}_{score_type.lower()}.pickle\"))\n",
    "    \n",
    "    # 4. Feature contributions for all individuals (heatmap)\n",
    "    contrib_heatmap = xpl.plot.contribution_plot(max_features=10)\n",
    "    plt.title(f\"Feature Contributions - {model_name.upper()} - {score_type}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"feature_contributions.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Interactive dashboard (only works in notebook)\n",
    "    print(\"To launch interactive dashboard, run: app = xpl.run_app()\")\n",
    "    \n",
    "    # Return the explainer for further analysis\n",
    "    return xpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing LIGHTGBM model for FRIED\n",
      "==================================================\n",
      "Model file not found for lightgbm - FRIED\n"
     ]
    }
   ],
   "source": [
    "# Get the explainer for a specific model (for example, lightgbm and FRIED)\n",
    "xpl = analyze_model('lightgbm', 'FRIED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing LIGHTGBM model for FRIED\n",
      "==================================================\n",
      "Model file not found for lightgbm - FRIED\n",
      "\n",
      "==================================================\n",
      "Analyzing LIGHTGBM model for FRAGIRE18\n",
      "==================================================\n",
      "Model file not found for lightgbm - FRAGIRE18\n",
      "\n",
      "==================================================\n",
      "Analyzing CATBOOST model for FRIED\n",
      "==================================================\n",
      "Model file not found for catboost - FRIED\n",
      "\n",
      "==================================================\n",
      "Analyzing CATBOOST model for FRAGIRE18\n",
      "==================================================\n",
      "Model file not found for catboost - FRAGIRE18\n",
      "\n",
      "==================================================\n",
      "Analyzing RANDOMFOREST model for FRIED\n",
      "==================================================\n",
      "Model file not found for randomforest - FRIED\n",
      "\n",
      "==================================================\n",
      "Analyzing RANDOMFOREST model for FRAGIRE18\n",
      "==================================================\n",
      "Model file not found for randomforest - FRAGIRE18\n",
      "\n",
      "Analysis complete. Visualizations saved in the respective model/score directories.\n"
     ]
    }
   ],
   "source": [
    "# Run analysis for all models and score types\n",
    "for model_name in MODELS:\n",
    "    for score_type in SCORE_TYPES:\n",
    "        try:\n",
    "            analyze_model(model_name, score_type)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {model_name} - {score_type}: {str(e)}\")\n",
    "\n",
    "print(\"\\nAnalysis complete. Visualizations saved in the respective model/score directories.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
